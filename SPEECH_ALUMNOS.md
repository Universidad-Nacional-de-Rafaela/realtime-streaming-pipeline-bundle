# ğŸ¤ Speech para Alumnos - Pipeline de Streaming en Tiempo Real

---

## ğŸ“¢ **INTRODUCCIÃ“N**

Buenos dÃ­as/tardes. Hoy vamos a explorar juntos un **pipeline de procesamiento de datos en tiempo real**, una arquitectura fundamental en la industria moderna para manejar datos que se generan continuamente.

Â¿Han escuchado hablar de Netflix analizando quÃ© ven en tiempo real? Â¿O Uber procesando millones de viajes simultÃ¡neamente? Â¿O sensores IoT enviando datos de temperatura constantemente? Todos estos sistemas utilizan arquitecturas similares a la que veremos hoy.

---

## ğŸ¯ **Â¿QUÃ‰ VAMOS A CONSTRUIR?**

Vamos a simular un sistema de **monitoreo de sensores IoT** que:
- Genera lecturas de temperatura y humedad
- Las procesa en tiempo real
- Las valida y transforma
- Las almacena para consultas posteriores

**La gran diferencia con sistemas tradicionales:** No esperamos a acumular datos para procesarlos al final del dÃ­a (batch processing). AquÃ­ procesamos **cada evento en el momento en que llega**.

---

## ğŸ—ï¸ **ARQUITECTURA DEL SISTEMA**

Nuestro pipeline tiene 5 componentes principales. Voy a explicar cada uno:

### **1. Kafka + Zookeeper** ğŸš€
**Â¿QuÃ© es?** Un sistema de mensajerÃ­a distribuido (message broker).

**Â¿Para quÃ© sirve?**
- ActÃºa como una **cola de mensajes** entre productores y consumidores
- Desacopla los componentes: el productor no necesita saber quiÃ©n consume los datos
- Funciona como un buffer: si Spark se cae, los mensajes se quedan en Kafka esperando
- **Alta throughput**: puede manejar millones de mensajes por segundo

**AnalogÃ­a:** Piensen en Kafka como un buzÃ³n inteligente. Los productores dejan mensajes (cartas), y los consumidores las recogen cuando estÃ¡n listos. Si el consumidor no estÃ¡, las cartas esperan.

**Zookeeper:** Es el coordinador de Kafka. Mantiene la metadata y coordina los brokers.

---

### **2. Productor de Datos (Python)** ğŸ“Š
**Â¿QuÃ© es?** Un script Python que simula sensores IoT.

**Â¿QuÃ© hace?**
- Genera 5 eventos por segundo (cada 200ms)
- Cada evento contiene:
  - `event_id`: identificador Ãºnico
  - `device_id`: ID del sensor (sensor-1 a sensor-50)
  - `ts`: timestamp
  - `temperature_c`: temperatura en Celsius (18-32Â°C)
  - `humidity_pct`: humedad en porcentaje (20-80%)

**Ejemplo de evento:**
```json
{
  "event_id": "1729107123456-7891",
  "device_id": "sensor-23",
  "ts": "2025-10-16T17:25:23.456000",
  "temperature_c": 24.57,
  "humidity_pct": 62.34
}
```

**En la vida real:** Estos serÃ­an sensores fÃ­sicos enviando datos desde fÃ¡bricas, ciudades inteligentes, hospitales, etc.

---

### **3. Apache Spark Structured Streaming** âš¡
**Â¿QuÃ© es?** El motor de procesamiento en tiempo real.

**Â¿QuÃ© hace?**
1. **Lee** eventos desde el topic de Kafka (`sensors.events`)
2. **Transforma** los datos:
   - Normaliza el device_id a lowercase
   - Convierte tipos de datos (strings a float, etc.)
   - Parsea timestamps
3. **Valida** los datos:
   - Rechaza eventos con campos vacÃ­os
   - Rechaza eventos con valores None o invÃ¡lidos
4. **Escribe** los datos validados en Cassandra

**Concepto clave: Micro-batches**
Spark no procesa evento por evento. Agrupa eventos en **micro-batches** pequeÃ±os (ej: 2 segundos de datos) y los procesa juntos. Esto es mÃ¡s eficiente que procesar uno a uno.

**Â¿Por quÃ© Spark?**
- Procesamiento distribuido (puede escalar a mÃºltiples mÃ¡quinas)
- APIs de alto nivel (fÃ¡cil de programar)
- Tolerancia a fallos
- IntegraciÃ³n con todo el ecosistema big data

---

### **4. Apache Cassandra** ğŸ’¾
**Â¿QuÃ© es?** Una base de datos NoSQL distribuida.

**Â¿Por quÃ© Cassandra y no PostgreSQL?**
- **Alta disponibilidad**: no hay single point of failure
- **Escalabilidad lineal**: agregar nodos aumenta capacidad proporcionalmente
- **Escrituras muy rÃ¡pidas**: optimizada para inserciones masivas
- **Modelo de datos flexible**: ideal para series temporales

**Nuestro schema:**
```sql
CREATE TABLE rt.sensor_readings (
  event_id text PRIMARY KEY,
  device_id text,
  ts timestamp,
  temperature_c double,
  humidity_pct double
);
```

**ExplicaciÃ³n:**
- `event_id` es la PRIMARY KEY: cada evento es Ãºnico
- Cassandra distribuye datos basÃ¡ndose en la PRIMARY KEY
- Perfecta para insert-heavy workloads (como datos de sensores)

---

### **5. Apache Airflow** ğŸ“…
**Â¿QuÃ© es?** Una plataforma de orquestaciÃ³n de workflows.

**Â¿Para quÃ© la usamos?**
- **Monitoreo**: ejecuta checks de salud de la infraestructura
- **Scheduling**: tareas programadas (nuestro DAG corre diariamente)
- **Alertas**: puede notificar si algo falla

**Nuestro DAG:**
- Verifica que Cassandra estÃ© respondiendo correctamente
- Se ejecuta todos los dÃ­as a las 00:00
- Si falla, puede reintentarlo o alertar al equipo

**En producciÃ³n:** Airflow tambiÃ©n se usa para:
- Entrenar modelos de ML periÃ³dicamente
- Generar reportes
- Ejecutar backfills de datos histÃ³ricos

---

## ğŸ”„ **FLUJO DE DATOS COMPLETO**

Ahora conectemos todas las piezas. Este es el journey de un evento:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. PRODUCTOR   â”‚  Genera evento JSON cada 200ms
â”‚   (Python)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ (envÃ­a a Kafka via network)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   2. KAFKA      â”‚  Almacena mensaje en topic "sensors.events"
â”‚   (Topic)       â”‚  El mensaje espera ser consumido
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ (Spark lee continuamente)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   3. SPARK      â”‚  Lee micro-batch desde Kafka
â”‚   (Streaming)   â”‚  â†“
â”‚                 â”‚  Aplica normalize_record():
â”‚                 â”‚    - event_id â†’ strip()
â”‚                 â”‚    - device_id â†’ lowercase
â”‚                 â”‚    - temperature_c â†’ float
â”‚                 â”‚    - humidity_pct â†’ float
â”‚                 â”‚  â†“
â”‚                 â”‚  Aplica is_valid():
â”‚                 â”‚    - Â¿campos no vacÃ­os?
â”‚                 â”‚    - Â¿valores no None?
â”‚                 â”‚  â†“
â”‚                 â”‚  Convierte tipos Spark:
â”‚                 â”‚    - ts â†’ timestamp
â”‚                 â”‚    - temperature_c â†’ double
â”‚                 â”‚    - humidity_pct â†’ double
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ (escribe a Cassandra)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. CASSANDRA   â”‚  INSERT INTO rt.sensor_readings
â”‚   (Database)    â”‚  Datos persistidos y consultables
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ (Airflow monitorea)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. AIRFLOW     â”‚  Verifica salud de Cassandra
â”‚  (Monitoring)   â”‚  Alerta si hay problemas
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tiempos aproximados:**
- Productor â†’ Kafka: **< 5ms**
- Kafka â†’ Spark (micro-batch): **2-5 segundos**
- Spark â†’ Cassandra: **< 100ms**
- **Latencia end-to-end: ~3-5 segundos**

En sistemas reales optimizados, esto puede bajar a sub-segundo.

---

## ğŸš€ **PASO A PASO DE LA DEMOSTRACIÃ“N**

Ahora vamos a verlo en acciÃ³n. Voy a guiarlos paso a paso:

### **PASO 1: Levantar la Infraestructura**

```bash
docker compose up -d
```

**Â¿QuÃ© sucede aquÃ­?**
- Docker Compose lee el archivo `docker-compose.yml`
- Crea una red privada para que los contenedores se comuniquen
- Levanta 6 contenedores:
  1. **zookeeper**: coordinador de Kafka
  2. **kafka**: message broker
  3. **cassandra**: base de datos
  4. **spark**: motor de procesamiento
  5. **airflow-webserver**: UI web de Airflow
  6. **airflow-scheduler**: scheduler de Airflow

**Tiempo de inicio:** 1-2 minutos (Cassandra es el mÃ¡s lento en iniciar)

---

### **PASO 2: Inicializar Kafka y Cassandra**

```bash
./scripts/init.sh
```

**Â¿QuÃ© hace este script?**
1. **Espera** a que Kafka estÃ© listo (hace polling hasta que responda)
2. **Crea el topic** `sensors.events` en Kafka
3. **Espera** a que Cassandra estÃ© lista
4. **Carga el schema** (crea el keyspace `rt` y la tabla `sensor_readings`)

**Â¿Por quÃ© este paso?**
Los contenedores pueden estar "UP" pero no listos para recibir conexiones. Este script asegura que todo estÃ© realmente funcional antes de empezar.

---

### **PASO 3: Ejecutar el Productor**

```bash
python app/producer/kafka_producer.py
```

**Â¿QuÃ© verÃ¡n?**
```
Producing to topic sensors.events at localhost:29092 ... Ctrl+C to stop
```

**Â¿QuÃ© estÃ¡ pasando internamente?**
1. El productor se conecta a Kafka en el puerto 29092 (puerto externo)
2. Entra en un loop infinito:
   ```python
   while True:
       evt = make_event()          # Genera datos aleatorios
       producer.send(TOPIC, evt)   # EnvÃ­a a Kafka
       time.sleep(0.2)             # Espera 200ms
   ```
3. Kafka confirma la recepciÃ³n (acks="all")
4. El mensaje queda guardado en el topic

**Configuraciones importantes del productor:**
- `acks="all"`: espera confirmaciÃ³n de todos los brokers (mÃ¡s seguro)
- `enable_idempotence=True`: evita duplicados
- `retries=3`: reintenta si falla
- `linger_ms=50`: agrupa mensajes para eficiencia

---

### **PASO 4: Observar Spark Procesando**

```bash
docker logs -f realtime_streaming_pipeline_bundle-spark-1
```

**Â¿QuÃ© verÃ¡n en los logs?**
```
25/10/16 17:30:34 INFO KafkaSourceProvider: Kafka version: 3.4.1
25/10/16 17:30:35 INFO ConsumerConfig: bootstrap.servers = [kafka:9092]
25/10/16 17:30:38 INFO MicroBatchExecution: Streaming query made progress:
  {
    "batchId" : 0,
    "numInputRows" : 25,
    "processedRowsPerSecond" : 5.2
  }
```

**ExplicaciÃ³n:**
- **KafkaSourceProvider**: Spark se conectÃ³ a Kafka
- **ConsumerConfig**: configuraciÃ³n del consumer (grupo, offsets, etc.)
- **MicroBatchExecution**: procesa micro-batches continuamente
- **numInputRows**: cuÃ¡ntos eventos procesÃ³ en ese batch
- **processedRowsPerSecond**: throughput actual

**Concepto clave: Checkpointing**
Spark guarda su progreso en `/tmp/chk/sensors`. Si Spark se cae y se reinicia, puede continuar desde donde quedÃ³ sin reprocesar datos.

---

### **PASO 5: Verificar Datos en Cassandra**

```bash
docker exec -it realtime_streaming_pipeline_bundle-cassandra-1 cqlsh
```

Esto abre una shell interactiva de Cassandra. Luego ejecutamos:

```sql
SELECT * FROM rt.sensor_readings LIMIT 5;
```

**Â¿QuÃ© verÃ¡n?**
```
 event_id              | device_id  | humidity_pct | temperature_c | ts
-----------------------+------------+--------------+---------------+---------
 1729107123456-7891    | sensor-23  |        62.34 |         24.57 | 2025-...
 1729107123657-3421    | sensor-08  |        45.12 |         28.91 | 2025-...
 ...
```

**Pregunta para reflexionar:** Â¿Notaron que el orden puede parecer aleatorio? Esto es porque Cassandra distribuye datos basÃ¡ndose en el hash de la PRIMARY KEY, no por tiempo de inserciÃ³n.

**Otras queries interesantes:**
```sql
-- Contar eventos totales
SELECT COUNT(*) FROM rt.sensor_readings;

-- Ãšltimos eventos (limitado, no ordenado)
SELECT * FROM rt.sensor_readings LIMIT 10;

-- Buscar un sensor especÃ­fico
SELECT * FROM rt.sensor_readings WHERE device_id = 'sensor-23' ALLOW FILTERING;
```

**Nota sobre ALLOW FILTERING:** En producciÃ³n evitarÃ­amos esto. Es ineficiente porque Cassandra escanea todos los nodos. Lo correcto serÃ­a incluir `device_id` en la PRIMARY KEY si lo vamos a consultar frecuentemente.

---

### **PASO 6: Ver Mensajes Raw en Kafka (Opcional)**

```bash
docker exec realtime_streaming_pipeline_bundle-kafka-1 \
  kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic sensors.events \
  --from-beginning \
  --max-messages 3
```

**Â¿QuÃ© verÃ¡n?**
```json
{"event_id":"1729...","device_id":"sensor-23","ts":"2025-...","temperature_c":24.57,"humidity_pct":62.34}
{"event_id":"1729...","device_id":"sensor-08","ts":"2025-...","temperature_c":28.91,"humidity_pct":45.12}
```

**Esto muestra:** Los mensajes tal como estÃ¡n almacenados en Kafka, antes de cualquier procesamiento.

---

### **PASO 7: Explorar Airflow UI**

Abrir navegador: **http://localhost:8080**

**Login:**
- Usuario: `admin`
- ContraseÃ±a: `admin`

**Â¿QuÃ© verÃ¡n?**
- Dashboard principal con el DAG `sanity_checks`
- Graph view: visualizaciÃ³n del DAG
- Grid view: historial de ejecuciones
- Logs de cada task

**Activar el DAG:**
Hagan click en el toggle para activarlo. VerÃ¡n que se ejecuta diariamente.

**Explorar una ejecuciÃ³n:**
- Click en una ejecuciÃ³n (verde = success, rojo = failed)
- Ver logs de la task `cassandra_check`
- Logs mostrarÃ¡n "Cassandra OK" si todo funciona

---

## ğŸ§ª **EXPERIMENTOS PARA PROFUNDIZAR**

### **Experimento 1: Resiliencia de Kafka**

**Objetivo:** Demostrar que Kafka actÃºa como buffer.

**Pasos:**
1. El productor estÃ¡ corriendo y enviando datos
2. Detenemos Spark: `docker stop realtime_streaming_pipeline_bundle-spark-1`
3. Esperamos 30 segundos (el productor sigue enviando a Kafka)
4. Reiniciamos Spark: `docker start realtime_streaming_pipeline_bundle-spark-1`
5. Observamos los logs de Spark

**Â¿QuÃ© verÃ¡n?**
Spark procesa un batch grande con todos los mensajes acumulados. **Â¡No se perdiÃ³ ningÃºn dato!**

**LecciÃ³n:** Kafka desacopla productor y consumidor. El sistema es resiliente a fallos temporales.

---

### **Experimento 2: ValidaciÃ³n de Datos**

**Objetivo:** Ver cÃ³mo Spark rechaza datos invÃ¡lidos.

**Modificar el productor:**
```python
# En kafka_producer.py, dentro del loop while True:
if random.random() < 0.1:  # 10% de eventos invÃ¡lidos
    evt = {
        "event_id": "",  # InvÃ¡lido: vacÃ­o
        "device_id": "sensor-99",
        "ts": "2025-01-01T00:00:00",
        "temperature_c": None,  # InvÃ¡lido: None
        "humidity_pct": 50.0
    }
```

**Ejecutar y observar:**
- Ver logs de Spark: algunos batches procesan menos eventos
- Consultar Cassandra: los eventos invÃ¡lidos NO aparecen

**LecciÃ³n:** La validaciÃ³n en Spark protege la calidad de datos en Cassandra.

---

### **Experimento 3: Escalabilidad del Productor**

**Objetivo:** Ver cÃ³mo el sistema maneja mÃ¡s carga.

**Modificar la frecuencia:**
```python
# En kafka_producer.py, cambiar:
time.sleep(0.2)  # Original: 5 eventos/seg
time.sleep(0.02)  # Nuevo: 50 eventos/seg
```

**Ejecutar mÃºltiples productores en paralelo:**
```bash
# Terminal 1
python app/producer/kafka_producer.py

# Terminal 2
python app/producer/kafka_producer.py

# Terminal 3
python app/producer/kafka_producer.py
```

**Observar:**
- Logs de Spark: `processedRowsPerSecond` aumenta
- Kafka maneja la carga sin problemas
- Cassandra recibe mÃ¡s escrituras

**LecciÃ³n:** La arquitectura puede escalar horizontalmente agregando mÃ¡s productores.

---

### **Experimento 4: Monitoreo en Tiempo Real**

**Objetivo:** Ver el crecimiento de datos en vivo.

**Ejecutar en una terminal:**
```bash
watch -n 2 'docker exec realtime_streaming_pipeline_bundle-cassandra-1 \
  cqlsh -e "SELECT COUNT(*) FROM rt.sensor_readings;"'
```

**Â¿QuÃ© verÃ¡n?**
Cada 2 segundos, el contador aumenta:
```
 count
-------
   125

 count
-------
   150

 count
-------
   175
```

**LecciÃ³n:** VisualizaciÃ³n del pipeline funcionando end-to-end en tiempo real.

---

## ğŸ’¡ **CONCEPTOS CLAVE PARA LLEVARSE**

### **1. Stream Processing vs Batch Processing**

**Batch (tradicional):**
- Procesa datos acumulados periÃ³dicamente (cada hora, dÃ­a)
- Latencia alta (esperas hasta el prÃ³ximo batch)
- Ejemplo: reporte de ventas diario

**Stream (moderno):**
- Procesa datos continuamente a medida que llegan
- Latencia baja (segundos o menos)
- Ejemplo: detecciÃ³n de fraude en tarjetas de crÃ©dito

**Â¿CuÃ¡ndo usar cada uno?**
- **Batch**: reportes histÃ³ricos, anÃ¡lisis no urgentes, modelos ML que entrenan con datos completos
- **Stream**: monitoreo en tiempo real, alertas, dashboards live, recomendaciones instantÃ¡neas

---

### **2. Desacoplamiento con Message Queues**

**Sin Kafka:**
```
Productor â†’ (conexiÃ³n directa) â†’ Spark â†’ Cassandra
```
Problemas:
- Si Spark cae, el productor debe manejar reintentos
- Si Spark estÃ¡ lento, el productor se bloquea
- DifÃ­cil agregar nuevos consumidores

**Con Kafka:**
```
Productor â†’ Kafka â†’ Spark â†’ Cassandra
                  â†˜ Otro Consumer (ej: Analytics)
```
Ventajas:
- Productor solo se preocupa de enviar a Kafka
- Kafka hace buffering si Spark estÃ¡ lento
- MÃºltiples consumidores pueden leer el mismo stream
- Componentes evolucionan independientemente

---

### **3. Data Validation & Quality**

**Principio: "Garbage In, Garbage Out"**

Si guardamos datos invÃ¡lidos en Cassandra:
- Queries fallan o retornan resultados incorrectos
- Dashboards muestran informaciÃ³n errÃ³nea
- Modelos de ML aprenden de datos malos

**Nuestra estrategia:**
1. **NormalizaciÃ³n**: convertir a formatos estÃ¡ndar (lowercase, trim, etc.)
2. **ValidaciÃ³n**: rechazar datos con campos faltantes o invÃ¡lidos
3. **Type casting**: asegurar tipos de datos correctos

**En producciÃ³n, agregar:**
- ValidaciÃ³n de rangos (temperatura entre -50 y 60Â°C)
- DeduplicaciÃ³n (evitar eventos duplicados)
- Esquemas formales (Avro, Protobuf)

---

### **4. Tolerancia a Fallos**

**Â¿QuÃ© puede fallar?**
- Kafka: broker puede caer
- Spark: worker puede quedarse sin memoria
- Cassandra: nodo puede perder conexiÃ³n
- Network: particiones de red

**Â¿CÃ³mo el sistema se protege?**
- **Kafka**: replica datos en mÃºltiples brokers
- **Spark**: checkpointing + exactly-once semantics
- **Cassandra**: replicaciÃ³n + eventual consistency
- **Contenedores**: Docker restart policies

**En producciÃ³n:**
- MÃºltiples brokers de Kafka (3-5)
- Cluster de Spark (1 master, N workers)
- Ring de Cassandra (3+ nodos)
- Monitoreo con Prometheus/Grafana
- Alertas automÃ¡ticas (PagerDuty, Slack)

---

### **5. Escalabilidad**

**Â¿CÃ³mo escalar cada componente?**

**Kafka:**
- Agregar mÃ¡s brokers
- Aumentar particiones del topic (paralelismo)
- Cada particiÃ³n puede ser leÃ­da por un consumer diferente

**Spark:**
- Agregar mÃ¡s workers al cluster
- Aumentar `spark.sql.shuffle.partitions`
- Usar mÃ¡s memoria por executor

**Cassandra:**
- Agregar mÃ¡s nodos al ring
- Datos se redistribuyen automÃ¡ticamente
- Escrituras y lecturas se distribuyen

**Resultado:** Escalabilidad casi lineal. 2x recursos â‰ˆ 2x throughput.

---

## ğŸ“ **PREGUNTAS PARA REFLEXIONAR**

Les dejo estas preguntas para que piensen:

1. **Arquitectura:**
   - Â¿QuÃ© pasarÃ­a si eliminamos Kafka y conectamos el productor directamente a Spark?
   - Â¿PodrÃ­amos reemplazar Cassandra con PostgreSQL? Â¿QuÃ© ventajas/desventajas?

2. **Data Quality:**
   - Â¿QuÃ© otras validaciones agregarÃ­an a los datos de sensores?
   - Â¿DeberÃ­amos guardar los eventos invÃ¡lidos en algÃºn lado? Â¿Para quÃ©?

3. **Escalabilidad:**
   - Â¿CÃ³mo escalarÃ­amos para 1 millÃ³n de sensores enviando datos por segundo?
   - Â¿QuÃ© componente serÃ­a el cuello de botella primero?

4. **Casos de Uso:**
   - Â¿QuÃ© modificaciones harÃ­an para procesar tweets en tiempo real?
   - Â¿CÃ³mo adaptarÃ­an esto para un sistema de monitoreo de servidores?

5. **EvoluciÃ³n:**
   - Â¿DÃ³nde agregarÃ­an machine learning? (ej: detectar anomalÃ­as en temperatura)
   - Â¿CÃ³mo implementarÃ­an un dashboard en tiempo real con estos datos?

---

## ğŸ“š **RECURSOS PARA SEGUIR APRENDIENDO**

### **DocumentaciÃ³n Oficial:**
- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [Spark Structured Streaming Guide](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [Cassandra Documentation](https://cassandra.apache.org/doc/latest/)
- [Airflow Documentation](https://airflow.apache.org/docs/)

### **Tutoriales y Cursos:**
- Kafka: "Kafka: The Definitive Guide" (libro)
- Spark: "Learning Spark" (libro, O'Reilly)
- Cassandra: DataStax Academy (cursos gratuitos)

### **Proyectos para Practicar:**
1. Agregar un dashboard con Streamlit o Grafana
2. Implementar alertas (ej: si temperatura > 30Â°C)
3. Agregar un modelo ML que prediga fallos de sensores
4. Procesar tweets en tiempo real y hacer anÃ¡lisis de sentimiento
5. Crear un sistema de monitoreo de logs de aplicaciones

---

## ğŸ¯ **CONCLUSIÃ“N**

Hoy vieron:
âœ… Una arquitectura moderna de streaming end-to-end
âœ… CÃ³mo 5 tecnologÃ­as (Kafka, Spark, Cassandra, Airflow, Docker) trabajan juntas
âœ… Los conceptos de desacoplamiento, validaciÃ³n, tolerancia a fallos
âœ… Un sistema escalable desde 5 eventos/seg hasta millones

**Lo mÃ¡s importante:** Esta NO es solo una demo acadÃ©mica. Es una arquitectura real utilizada por empresas como:
- **Uber**: tracking de viajes en tiempo real
- **Netflix**: anÃ¡lisis de visualizaciÃ³n y recomendaciones
- **LinkedIn**: feed de actividad en tiempo real
- **Spotify**: recomendaciones de mÃºsica

**PrÃ³ximos pasos:**
1. Ejecuten la demo ustedes mismos
2. Experimenten con las modificaciones propuestas
3. Piensen en un proyecto personal usando esta arquitectura
4. Profundicen en el componente que mÃ¡s les interesÃ³

**Â¡Estoy disponible para preguntas!**

---

## ğŸ› ï¸ **COMANDOS DE REFERENCIA RÃPIDA**

```bash
# Iniciar todo
docker compose up -d
./scripts/init.sh

# Ejecutar productor
python app/producer/kafka_producer.py

# Ver logs de Spark
docker logs -f realtime_streaming_pipeline_bundle-spark-1

# Conectar a Cassandra
docker exec -it realtime_streaming_pipeline_bundle-cassandra-1 cqlsh

# Ver mensajes en Kafka
docker exec realtime_streaming_pipeline_bundle-kafka-1 \
  kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic sensors.events \
  --from-beginning \
  --max-messages 5

# Monitoreo en tiempo real
watch -n 2 'docker exec realtime_streaming_pipeline_bundle-cassandra-1 \
  cqlsh -e "SELECT COUNT(*) FROM rt.sensor_readings;"'

# Detener todo
docker compose down -v
```

---

**Â¡Gracias y Ã©xitos en sus proyectos!** ğŸš€

