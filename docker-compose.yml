version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports: ["2181:2181"]

  kafka:
    image: confluentinc/cp-kafka:7.5.1
    depends_on: [zookeeper]
    ports: ["9092:9092", "29092:29092"]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

  cassandra:
    image: cassandra:4.1
    ports: ["9042:9042"]
    environment:
      - MAX_HEAP_SIZE=1G
      - HEAP_NEWSIZE=256M
    volumes:
      - ./cassandra/schema.cql:/schema.cql
      - ./cassandra/init-schema.sh:/init-schema.sh
    healthcheck:
      test: ["CMD-SHELL", "cqlsh -e 'describe cluster' || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 40s

  cassandra-init:
    image: cassandra:4.1
    depends_on:
      cassandra:
        condition: service_healthy
    volumes:
      - ./cassandra/schema.cql:/schema.cql
      - ./cassandra/init-schema.sh:/init-schema.sh
    command: ["/bin/bash", "/init-schema.sh"]
    restart: "no"
    links:
      - cassandra

  spark:
    image: apache/spark:3.5.1
    depends_on:
      kafka:
        condition: service_started
      cassandra:
        condition: service_healthy
      cassandra-init:
        condition: service_completed_successfully
    user: root
    volumes:
      - ./app/spark:/opt/app
    entrypoint: ["/bin/sh", "-c"]
    command:
      - "sleep 30 && /opt/spark/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,com.datastax.spark:spark-cassandra-connector_2.12:3.5.1 --conf spark.sql.shuffle.partitions=2 /opt/app/streaming_job.py"
    links:
      - kafka
      - cassandra

  airflow-webserver:
    image: apache/airflow:2.9.2
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__SECRET_KEY=devsecret
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
    depends_on: []
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - airflow-data:/opt/airflow
    ports:
      - "8080:8080"
    command:
      - bash
      - -c
      - |
        pip install --no-cache-dir cassandra-driver &&
        airflow db init &&
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com 2>/dev/null || true &&
        airflow webserver

  airflow-scheduler:
    image: apache/airflow:2.9.2
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__SECRET_KEY=devsecret
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
    depends_on: [airflow-webserver]
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - airflow-data:/opt/airflow
    command:
      - bash
      - -c
      - |
        pip install --no-cache-dir cassandra-driver &&
        sleep 30 && airflow scheduler

  redpanda-console:
    image: redpandadata/console:latest
    depends_on: [kafka]
    ports:
      - "8081:8080"
    environment:
      - KAFKA_BROKERS=kafka:9092
    restart: unless-stopped

  cassandra-web:
    image: ipushc/cassandra-web:latest
    depends_on:
      cassandra:
        condition: service_healthy
    ports:
      - "8082:8083"
    environment:
      - CASSANDRA_HOST=cassandra
      - CASSANDRA_PORT=9042
      - CASSANDRA_USERNAME=cassandra
      - CASSANDRA_PASSWORD=cassandra
    restart: unless-stopped

volumes:
  airflow-data:
